\begin{thebibliography}{1}

\bibitem{cfo1989}
Michael McCloskey and Neal~J. Cohen.
\newblock Catastrophic interference in connectionist networks: The sequential
  learning problem.
\newblock volume~24 of {\em Psychology of Learning and Motivation}, pages
  109--165. Academic Press, 1989.

\bibitem{pretrain}
K.~McRae and A.~Hetherington.
\newblock Catastrophic interference is eliminated in pretrained networks.
\newblock 1993.

\bibitem{generative}
Hanul Shin, Jung~Kwon Lee, Jaehong Kim, and Jiwon Kim.
\newblock Continual learning with deep generative replay.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, NIPS'17, page 2994â€“3003, Red Hook, NY,
  USA, 2017. Curran Associates Inc.

\bibitem{ewc}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
  Desjardins, Andrei~A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
  Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and
  Raia Hadsell.
\newblock Overcoming catastrophic forgetting in neural networks, 2017.

\bibitem{empirical}
Frederik Kunstner, Lukas Balles, and Philipp Hennig.
\newblock Limitations of the empirical fisher approximation for natural
  gradient descent, 2020.

\end{thebibliography}
